{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633962b3",
   "metadata": {},
   "source": [
    "# Yankees 2023 — Rolling xwOBA & Comparable Players\n",
    "\n",
    "This notebook does two things:\n",
    "\n",
    "1. **Rolling xwOBA** per hitter for the New York Yankees in **2023** (from pitch-level Statcast).\n",
    "2. **Comparable players** using **cosine similarity** on **season-level** features.\n",
    "\n",
    "It is designed to run inside this repo:\n",
    "- Looks for raw Statcast in `data/raw/` (e.g., `statcast_NYY_2023.csv` or `statcast_ALL_2023.csv`).\n",
    "- Falls back to `sample_data/` when possible.\n",
    "- If raw is missing, you can (optionally) fetch via `pybaseball` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f14dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROC_DIR = DATA_DIR / \"processed\"\n",
    "SAMPLE_DIR = Path(\"sample_data\")\n",
    "\n",
    "TEAM = \"NYY\"\n",
    "YEAR = 2023\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff46085",
   "metadata": {},
   "source": [
    "## Locate raw Statcast for 2023\n",
    "\n",
    "We try, in order:\n",
    "1) `data/raw/statcast_NYY_2023.csv`  \n",
    "2) any `data/raw/statcast_*_2023.csv` (league-wide or other team)  \n",
    "3) `sample_data/` fallback (if provided)\n",
    "\n",
    "If none exist, run the **optional fetch cell** to download via `pybaseball` (local-only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeeec50",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Find a suitable raw CSV for 2023\n",
    "raw_path = None\n",
    "preferred = RAW_DIR / f\"statcast_{TEAM}_{YEAR}.csv\"\n",
    "if preferred.exists():\n",
    "    raw_path = preferred\n",
    "else:\n",
    "    cands = sorted(RAW_DIR.glob(f\"statcast_*_{YEAR}.csv\"))\n",
    "    raw_path = cands[0] if cands else None\n",
    "\n",
    "raw_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3041de06",
   "metadata": {},
   "source": [
    "### (Optional) Fetch via `pybaseball` if raw is missing\n",
    "\n",
    "> This requires internet access and will write to `data/raw/` using monthly chunks (friendly to the source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06122078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2023-03-01 → 2023-03-31\n",
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Fetch raw 2023 for NYY if not present\n",
    "# Uncomment and run if needed.\n",
    "from pybaseball import statcast\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "months = [(3,31),(4,30),(5,31),(6,30),(7,31),(8,31),(9,30),(10,31)]\n",
    "frames = []\n",
    "for m, last_day in months:\n",
    "    start = f\"{YEAR}-{m:02d}-01\"\n",
    "    end   = f\"{YEAR}-{m:02d}-{last_day:02d}\"\n",
    "    print(\"Fetching\", start, \"→\", end)\n",
    "    df = statcast(start_dt=start, end_dt=end, team=TEAM)\n",
    "    frames.append(df)\n",
    "raw = pd.concat(frames, ignore_index=True)\n",
    "outp = RAW_DIR / f\"statcast_{TEAM}_{YEAR}.csv\"\n",
    "raw.to_csv(outp, index=False)\n",
    "raw_path = outp\n",
    "raw_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbb36f7",
   "metadata": {},
   "source": [
    "## Load raw with minimal columns\n",
    "\n",
    "Using `usecols` keeps I/O fast and the notebook portable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56139b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "usecols = [\n",
    "    \"game_date\",\"game_pk\",\"at_bat_number\",\n",
    "    \"batter\",\"player_name\",\"batter_name\",\"batter_full_name\",\n",
    "    \"estimated_woba_using_speedangle\",\"woba_value\",\"woba_denom\",\n",
    "    \"events\"\n",
    "]\n",
    "\n",
    "if raw_path and raw_path.exists():\n",
    "    header = pd.read_csv(raw_path, nrows=0).columns.tolist()\n",
    "    cols = [c for c in usecols if c in header]\n",
    "    sc = pd.read_csv(raw_path, usecols=cols, low_memory=False)\n",
    "else:\n",
    "    # try a small fallback (optional)\n",
    "    sc = pd.DataFrame()\n",
    "\n",
    "print(\"Raw Statcast shape:\", sc.shape)\n",
    "display(sc.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cefaae",
   "metadata": {},
   "source": [
    "## Build PA-level table & compute rolling xwOBA\n",
    "\n",
    "- **PA** defined as unique `(game_pk, at_bat_number)` with a non-null `events` value.\n",
    "- Rolling average uses `estimated_woba_using_speedangle` as a proxy for xwOBA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42349e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve columns\n",
    "name_col = next((c for c in [\"player_name\",\"batter_name\",\"batter_full_name\"] if c in sc.columns), None)\n",
    "id_col   = next((c for c in [\"batter\",\"batter_id\",\"batter_pk\"] if c in sc.columns), None)\n",
    "if name_col is None:\n",
    "    name_col = \"player_name\"\n",
    "    sc[name_col] = \"UNKNOWN\"\n",
    "if id_col is None:\n",
    "    sc[\"__pid__\"] = sc[name_col].fillna(\"UNKNOWN\").astype(\"category\").cat.codes\n",
    "    id_col = \"__pid__\"\n",
    "\n",
    "# Filter to rows with events and a date\n",
    "sc[\"game_date\"] = pd.to_datetime(sc.get(\"game_date\", pd.NaT), errors=\"coerce\")\n",
    "mask_evt = sc[\"events\"].notna() if \"events\" in sc.columns else False\n",
    "df = sc.loc[mask_evt].dropna(subset=[\"game_date\"]).copy()\n",
    "\n",
    "# Unique ABs\n",
    "ab = df[[\"game_pk\",\"at_bat_number\",\"estimated_woba_using_speedangle\", id_col, name_col, \"game_date\"]].drop_duplicates()\n",
    "ab = ab.sort_values([\"game_date\", id_col, \"at_bat_number\"]).reset_index(drop=True)\n",
    "\n",
    "# Top hitters by PA\n",
    "top = (ab.groupby([id_col, name_col]).size().rename(\"PA\")\n",
    "         .reset_index().sort_values(\"PA\", ascending=False).head(8))\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf88ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rolling xwOBA for top hitters\n",
    "ROLL = 50  # window in PAs (adjust if you prefer 25 or 75)\n",
    "for pid, pname in top[[id_col, name_col]].itertuples(index=False):\n",
    "    sub = ab[ab[id_col] == pid].copy()\n",
    "    x = sub[\"estimated_woba_using_speedangle\"]\n",
    "    rolling = x.rolling(ROLL, min_periods=max(5, ROLL//5)).mean()\n",
    "    plt.figure()\n",
    "    plt.plot(sub[\"game_date\"], rolling)\n",
    "    plt.title(f\"{pname} — Rolling xwOBA ({ROLL}-PA) — {YEAR} {TEAM}\")\n",
    "    plt.xlabel(\"Date\"); plt.ylabel(\"xwOBA (rolling)\")\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0912a0",
   "metadata": {},
   "source": [
    "## Comparable players (season-level features)\n",
    "\n",
    "We compute **cosine similarity** on standardized vectors using features:\n",
    "- `xwoba`, `avg_ev`, `k_rate`, `bb_rate`, `barrel_rate`\n",
    "\n",
    "Source: `data/processed/hitters_features.csv` (or `sample_data/hitters_features_sample.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load season-level features\n",
    "hit_path = PROC_DIR / \"hitters_features.csv\"\n",
    "if not hit_path.exists():\n",
    "    alt_path = Path(\"sample_data\") / \"hitters_features_sample.csv\"\n",
    "    hit_path = alt_path if alt_path.exists() else None\n",
    "\n",
    "if hit_path and Path(hit_path).exists():\n",
    "    hit = pd.read_csv(hit_path)\n",
    "    if \"season\" in hit.columns:\n",
    "        hit[\"season\"] = pd.to_numeric(hit[\"season\"], errors=\"coerce\").astype(\"Int64\")\n",
    "else:\n",
    "    hit = pd.DataFrame()\n",
    "\n",
    "print(\"Season-level features shape:\", hit.shape)\n",
    "display(hit.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bda854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build similarity on latest season available\n",
    "features = [\"xwoba\",\"avg_ev\",\"k_rate\",\"bb_rate\",\"barrel_rate\"]\n",
    "dfc = hit.dropna(subset=features).copy()\n",
    "for c in features:\n",
    "    dfc[c] = pd.to_numeric(dfc[c], errors=\"coerce\")\n",
    "dfc = dfc.dropna(subset=features)\n",
    "\n",
    "if not dfc.empty:\n",
    "    latest = int(dfc[\"season\"].dropna().max())\n",
    "    pool = dfc[dfc[\"season\"] == latest].copy()\n",
    "    # choose a target by highest PA\n",
    "    pool[\"pa\"] = pd.to_numeric(pool.get(\"pa\", np.nan), errors=\"coerce\")\n",
    "    tgt = pool.sort_values(\"pa\", ascending=False).head(1)\n",
    "    if not tgt.empty:\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        X = dfc[features].values\n",
    "        scaler = StandardScaler()\n",
    "        Xs = scaler.fit_transform(X)\n",
    "        sim = cosine_similarity(Xs)\n",
    "\n",
    "        idx = tgt.index[0]\n",
    "        s = pd.Series(sim[idx], index=dfc.index, name=\"similarity\").sort_values(ascending=False)\n",
    "        comps = (dfc.loc[s.index, [\"player_name\",\"season\"] + features]\n",
    "                   .assign(similarity=s.values)\n",
    "                   .head(10)\n",
    "                   .reset_index(drop=True))\n",
    "        print(\"Target:\", dfc.loc[idx, [\"player_name\",\"season\"]].to_dict())\n",
    "        display(comps.style.format({\"similarity\": \"{:.3f}\"}))\n",
    "else:\n",
    "    print(\"No season-level features found. Run the pipeline to create data/processed/hitters_features.csv.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc4615",
   "metadata": {},
   "source": [
    "> **Tip:** If you want comps restricted to Yankees: filter `dfc` to `team == 'NYY'` once you add a team column during feature building."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
